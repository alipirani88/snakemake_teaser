{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cecd68-ff14-43bf-a038-6b6af8813c76",
   "metadata": {},
   "source": [
    "## Getting started with Snakemake workflows for automated bioinformatics analysis.\n",
    "\n",
    "## Author: Ali Pirani\n",
    "\n",
    "## Software we're going to use\n",
    "\n",
    "We're going to be using [conda](https://conda.io/en/latest/) and [snakemake](https://snakemake.readthedocs.io/en/stable/), as well as packages from [bioconda](https://bioconda.github.io). \n",
    "\n",
    "If you wanted to run all of this on your own computer, you'll need to follow the bioconda install instructions.\n",
    "\n",
    "We'll be implementing a short read quality check and trimming pipeline, using [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/), [trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic), and [multiqc](https://multiqc.info/) to demonstrate how to get started with the Snakemake workflow. \n",
    "\n",
    "You can see the full set of installed software requirements in a conda `environment.yml` file located under binder directory. More on binder later.\n",
    "\n",
    "You could use this install file to run everything we're doing today on your laptop, with: \n",
    "```\n",
    "conda env create --file binder/environment.yml -n smake\n",
    "conda activate smake\n",
    "pip install bash_kernel\n",
    "python -m bash_kernel.install\n",
    "```\n",
    "\n",
    "Why use a workflow management tool?\n",
    "\n",
    "- Dependency management\n",
    "- Reentrancy - start back up where you left off\n",
    "- Reusable\n",
    "- Documented\n",
    "- Portable\n",
    "\n",
    "There are many to choose from: https://github.com/pditommaso/awesome-pipeline\n",
    "\n",
    "## Tasks we are going to do\n",
    "\n",
    "- Download data which we will use for Snakemake workflow\n",
    "- Create a Snakefile to write our first rule i.e running FastQC on fastq reads.\n",
    "- \n",
    "\n",
    "## Download some data\n",
    "\n",
    "Execute the below cell to fetch some data. This will download the example fastq data to your data directory.\n",
    "\n",
    "Note: To run bash commands, select bash kernel from the top right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abaad171-6a7a-47db-8178-bcb10f7480ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   190  100   190    0     0    688      0 --:--:-- --:--:-- --:--:--   688\n",
      "100 7689k  100 7689k    0     0  11.4M      0 --:--:-- --:--:-- --:--:-- 11.4M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   190  100   190    0     0    917      0 --:--:-- --:--:-- --:--:--   917\n",
      "100 5262k  100 5262k    0     0   9.8M      0 --:--:-- --:--:-- --:--:-- 16.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   190  100   190    0     0    745      0 --:--:-- --:--:-- --:--:--   745\n",
      "100 8160k  100 8160k    0     0  14.7M      0 --:--:-- --:--:-- --:--:-- 14.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   190  100   190    0     0    935      0 --:--:-- --:--:-- --:--:--   935\n",
      "100 5483k  100 5483k    0     0  11.5M      0 --:--:-- --:--:-- --:--:-- 11.5M\n"
     ]
    }
   ],
   "source": [
    "curl -L https://github.com/ctb/2019-snakemake-ucdavis/raw/9db09bc0b6a3469f8a0d4996d4b2995bf36e5d27/data/0Hour_001_1.fq.gz > data/0Hour_001_1.fq.gz\n",
    "curl -L https://github.com/ctb/2019-snakemake-ucdavis/raw/9db09bc0b6a3469f8a0d4996d4b2995bf36e5d27/data/6Hour_001_1.fq.gz > data/6Hour_001_1.fq.gz\n",
    "curl -L https://github.com/ctb/2019-snakemake-ucdavis/raw/9db09bc0b6a3469f8a0d4996d4b2995bf36e5d27/data/0Hour_001_2.fq.gz > data/0Hour_001_2.fq.gz\n",
    "curl -L https://github.com/ctb/2019-snakemake-ucdavis/raw/9db09bc0b6a3469f8a0d4996d4b2995bf36e5d27/data/6Hour_001_2.fq.gz > data/6Hour_001_2.fq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6d4028-e4e3-4c51-99bd-c135bc81f54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0Hour_001_1.fq.gz  0Hour_001_2.fq.gz  6Hour_001_1.fq.gz  6Hour_001_2.fq.gz\n"
     ]
    }
   ],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d00ad-9a1d-427c-be3c-cdd0ce9331f6",
   "metadata": {},
   "source": [
    "Lets activate the snakemake environment using conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a79f1e1-bdf3-41a9-8e75-eaa031b5f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(smake) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate smake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34e66d-3eb2-4c48-b863-e5146fab9e4b",
   "metadata": {},
   "source": [
    "## Running snakemake!\n",
    "\n",
    "### Create your first Snakefile.\n",
    "\n",
    "We will define our rules of workflow in a Snakefile. \n",
    "\n",
    "Create a new text file by selecting (`File`, `New`, `Text file`) from the the top left corner menu and copy/paste this first rule:\n",
    "\n",
    "```\n",
    "rule fastqc_a_file:\n",
    "  shell:\n",
    "    \"fastqc data/0Hour_001_1.fq.gz\"\n",
    "```\n",
    "\n",
    "Save and Rename it to \"Snakefile\". (Right click on the file from the file explorer in left panel and select Rename)\n",
    "\n",
    "* the snakemake configuration file is by default called `Snakefile`\n",
    "\n",
    "Now, run snakemake:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a0af9-ef2c-4610-bb8a-037d00ccf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56759a6e-a0d4-4eea-adf0-b775a3ad3bb1",
   "metadata": {},
   "source": [
    "What was the error?\n",
    "\n",
    "Lets run it with 1 core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae84bc0-acde-4507-84dc-bf09128b23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8d90e-c1ee-4215-9663-292ebdf2f272",
   "metadata": {},
   "source": [
    "You should see:\n",
    "\n",
    "```\n",
    "\n",
    "Building DAG of jobs...\n",
    "Using shell: /bin/bash\n",
    "Provided cores: 1 (use --cores to define parallelism)\n",
    "Rules claiming more threads will be scaled down.\n",
    "Job stats:\n",
    "job              count    min threads    max threads\n",
    "-------------  -------  -------------  -------------\n",
    "fastqc_a_file        1              1              1\n",
    "total                1              1              1\n",
    "\n",
    "Select jobs to execute...\n",
    "\n",
    "[Wed Nov  3 15:49:22 2021]\n",
    "rule fastqc_a_file:\n",
    "    jobid: 0\n",
    "    resources: tmpdir=/tmp\n",
    "\n",
    "Started analysis of 0Hour_001_1.fq.gz\n",
    "Approx 5% complete for 0Hour_001_1.fq.gz\n",
    "...\n",
    "Analysis complete for 0Hour_001_1.fq.gz\n",
    "[Wed Nov  3 15:49:27 2021]\n",
    "Finished job 0.\n",
    "1 of 1 steps (100%) done\n",
    "Complete log: /home/apirani/Session8_snakemake/.snakemake/log/2021-11-03T154921.245311.snakemake.log\n",
    "\n",
    "(smake) \n",
    "```\n",
    "\n",
    "### Updating the Snakefile to track inputs and outputs \n",
    "\n",
    "At the moment this is basically just a shell script with extra syntax... what's the point?\n",
    "\n",
    "Well, shell scripts - and this snakefile, too - will rerun the command every time you run the file, even if there's no reason to do so because the file hasn't changed.\n",
    "\n",
    "**Digression:** This is particularly important for large or long workflows, where you're dealing with 10s to 100s of files that may take hours to days to process! It can be hard to figure out which files to rerun, but (spoiler alert) snakemake can really help you do this!\n",
    "\n",
    "It's hard to track this kind of thing in a shell script - I usually just comment out the lines I don't want run, or break my commands up into multiple shell scripts so they don't take so long - but with snakemake, you can annotate the rule with input and output files! \n",
    "\n",
    "If you annotate the rule with input/output files, Snakemake will automatically check if the output file exists and makes a decision to either rerun or do nothing.\n",
    "\n",
    "We will see how it does that in the following section.\n",
    "\n",
    "Change your snakefile to look like this:\n",
    "\n",
    "```\n",
    "rule fastqc_a_file:\n",
    "  input:\n",
    "    \"data/0Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/0Hour_001_1_fastqc.html\",\n",
    "    \"data/0Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc data/0Hour_001_1.fq.gz\"\n",
    "```\n",
    "\n",
    "here, we've annotated the rule with the required\n",
    "**input** file, as well as the expected **output** files.\n",
    "\n",
    "Question: how do we know what the output files are?\n",
    "\n",
    "Now run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c8767-f7b7-45e2-83e9-ebc8a07d83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c995749-3834-4586-8e7a-e9f493065100",
   "metadata": {},
   "source": [
    "You should see something like this:\n",
    "\n",
    "```\n",
    "Building DAG of jobs...\n",
    "Nothing to be done.\n",
    "Complete log: /home/apirani/Session8_snakemake/.snakemake/log/2021-11-03T155832.508508.snakemake.log\n",
    "```\n",
    "\n",
    "What happened??\n",
    "\n",
    "snakemake looked at the file, saw that the output files existed, and figured out that it didn't need to do anything!\n",
    "\n",
    "### Forcibly re-running things\n",
    "\n",
    "You can tell snakemake to run the rule no matter what with `-f`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d6ce2-d880-4c49-8aa1-147b5f64b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake -f --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe90d6-a0a7-4a7b-b115-a085a16dec49",
   "metadata": {},
   "source": [
    "You can also remove an output file and it will automatically re-run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944eee8e-0b01-407b-b9ff-d710edfae087",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm data/*.html\n",
    "snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691a7f6-fcce-4a33-af72-1b7c81403cc4",
   "metadata": {},
   "source": [
    "Note that you don't need to remove *all* the output files to rerun a command - just remove *one* of them.\n",
    "\n",
    "You can *also* update the timestamp on an *input* file, and snakemake will figure out that the output file is older than the input file, and rerun things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297b7f9-03fe-4ae1-9e4a-45faa6272f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "touch data/*.fq.gz\n",
    "snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9509c2-b0dd-4fb7-950f-c671e1dc176e",
   "metadata": {},
   "source": [
    "This feature of Snakemake will become importanta later.\n",
    "\n",
    "### Multiple rules\n",
    "\n",
    "Let's add a rule to run fastqc on a second file:\n",
    "\n",
    "```\n",
    "rule fastqc_a_file:\n",
    "  input:\n",
    "    \"data/0Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/0Hour_001_1_fastqc.html\",\n",
    "    \"data/0Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc data/0Hour_001_1.fq.gz\"\n",
    "\n",
    "rule fastqc_a_file2:\n",
    "  input:\n",
    "    \"data/6Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/6Hour_001_1_fastqc.html\",\n",
    "    \"data/6Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc data/6Hour_001_1.fq.gz\"\n",
    "```\n",
    "\n",
    "Now run snakemake again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532e550-d915-4dc3-874d-33aaf31fef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aafd70-2d7f-45a8-86aa-b10cfc4760e3",
   "metadata": {},
   "source": [
    "What did snakemake do?\n",
    "\n",
    "- Snakemake will do nothing. Because By default, snakemake only runs the *first* rule in a Snakefile.\n",
    "\n",
    "How can you bypass this?\n",
    "\n",
    "- You can give a rule name on the command line, if you like, **or** you can tell snakemake what output file(s) you want.\n",
    "\n",
    "Lets do the latter and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fc155-0f8d-4f01-9cb9-2eef143ba998",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake --cores 1 data/0Hour_001_1_fastqc.html data/6Hour_001_1_fastqc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97252213-b66e-4495-83c2-615909e6190c",
   "metadata": {},
   "source": [
    "Now you should see the second fastqc command run, with the appropriate output files!\n",
    "\n",
    "Note that snakemake only runs the second rule, because it looks at the output files and sees that the first file you wanted, `0Hour_001_1_fastqc.html` already exists!\n",
    "\n",
    "Its a good feature when you are dealing with only few rules or while debugging your rules. The downside here is:\n",
    "\n",
    "* this is pretty long compared to the same shell script...\n",
    "* specifying which file or rule you want is kind of annoying...\n",
    "\n",
    "### A first refactoring: adding a better default rule\n",
    "\n",
    "Let's start refactoring (cleaning up) this Snakefile.\n",
    "\n",
    "First, let's add a rule at the top:\n",
    "\n",
    "```\n",
    "rule all:\n",
    "  input:\n",
    "    \"data/0Hour_001_1_fastqc.html\",\n",
    "    \"data/6Hour_001_1_fastqc.html\"\n",
    "\n",
    "rule fastqc_a_file:\n",
    "  input:\n",
    "    \"data/0Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/0Hour_001_1_fastqc.html\",\n",
    "    \"data/0Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc data/0Hour_001_1.fq.gz\"\n",
    "\n",
    "rule fastqc_a_file2:\n",
    "  input:\n",
    "    \"data/6Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/6Hour_001_1_fastqc.html\",\n",
    "    \"data/6Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc data/6Hour_001_1.fq.gz\"\n",
    "```\n",
    "\n",
    "This rule, by convention called `all`, is a default rule that produces all the final output files. \n",
    "\n",
    "But it's a bit weird! It's all input, and no output!\n",
    "\n",
    "Its a blank rule that gathers together all of the various files you want produced, and says \"hey, snakemake, I depend on all of these files for my input - make them for me!\" And then, once those files are all there, it ...does nothing.\n",
    "\n",
    "Yep, this is perfectly legal in snakemake, and it's one way to make your life easier.\n",
    "\n",
    "Note that `snakemake --cores 1 -f` no longer works properly, because `-f` only forces rerunning a single rule. \n",
    "\n",
    "To rerun everything, you can run `touch data/*.fq.gz` to make all the output files stale; or `rm data/*.html` to remove some of the output files.\n",
    "\n",
    "### A second refactoring: doing a bit of templating\n",
    "\n",
    "There's a lot of repetition in each of these rules. Let's collapse it down a little bit by replacing the filename in the fastqc command with a magic variable, `{input}`.\n",
    "\n",
    "```\n",
    "rule all:\n",
    "  input:\n",
    "    \"data/0Hour_001_1_fastqc.html\",\n",
    "    \"data/6Hour_001_1_fastqc.html\"\n",
    "\n",
    "rule fastqc_a_file:\n",
    "  input:\n",
    "    \"data/0Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/0Hour_001_1_fastqc.html\",\n",
    "    \"data/0Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc {input}\"\n",
    "\n",
    "rule fastqc_a_file2:\n",
    "  input:\n",
    "    \"data/6Hour_001_1.fq.gz\"\n",
    "  output:\n",
    "    \"data/6Hour_001_1_fastqc.html\",\n",
    "    \"data/6Hour_001_1_fastqc.zip\"\n",
    "  shell:\n",
    "    \"fastqc {input}\"\n",
    "```\n",
    "\n",
    "This all works as before, but now the rule is a bit more generic and will work with any input file. Sort of.\n",
    "\n",
    "The input files data/0Hour_001_1.fq.gz and data/6Hour_001_1.fq.gz are still hardcoded, the variable {input} means take files mentioned in the input section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10da79b-500f-4be5-bdcc-e206f48c047f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
